# -*- coding: utf-8 -*-
#!/usr/bin/env python3
"""
Segmenta√ß√£o de Pessoas em Tempo Real via Captura de Tela
=======================================================

Script para segmenta√ß√£o de pessoas usando YOLO11-seg.
Cria m√°scaras precisas da forma das pessoas detectadas.
Baseado na documenta√ß√£o: https://docs.ultralytics.com/pt/tasks/segment/
"""

import cv2
import numpy as np
from ultralytics import YOLO
import argparse
import time
import torch
import pyautogui
import os
import threading
from threading import Lock

class SegmentadorPessoas:
    """Classe para segmenta√ß√£o de pessoas em tempo real usando YOLOv8/YOLO11-seg."""
    
    def __init__(self, modelo="yolov8n-seg.pt", confianca=0.5, tamanho_img=640, resolucao_captura=0.5, tamanho_janela=(800, 600)):
        """
        Inicializa o segmentador de pessoas.
        
        Args:
            modelo: Modelo YOLOv8/YOLO11-seg (padr√£o: yolov8n-seg.pt)
            confianca: Limiar de confian√ßa (0.0 a 1.0)
            tamanho_img: Tamanho da imagem para infer√™ncia
            resolucao_captura: Fator de redu√ß√£o da resolu√ß√£o (0.1 a 1.0)
            tamanho_janela: Tamanho da janela de exibi√ß√£o (largura, altura)
        """
        # Verifica se CUDA est√° dispon√≠vel
        self.device = self._verificar_gpu()
        
        # Carrega o modelo de segmenta√ß√£o na GPU se dispon√≠vel
        print(f"üîÑ Carregando modelo de segmenta√ß√£o: {modelo}")
        self.modelo = self._carregar_modelo(modelo)
        if self.device == "cuda":
            self.modelo.to(self.device)
            print(f"‚úÖ GPU detectada: {torch.cuda.get_device_name()}")
            print(f"‚úÖ Mem√≥ria GPU: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
        else:
            print("‚ö†Ô∏è  GPU n√£o detectada - usando CPU (performance reduzida)")
        
        self.confianca = confianca
        self.tamanho_img = tamanho_img
        self.resolucao_captura = max(0.1, min(1.0, resolucao_captura))
        
        # Obt√©m resolu√ß√£o da tela
        self.largura_tela, self.altura_tela = pyautogui.size()
        self.largura_processada = int(self.largura_tela * self.resolucao_captura)
        self.altura_processada = int(self.altura_tela * self.resolucao_captura)
        
        # Calcula tamanho da janela mantendo propor√ß√£o
        self.tamanho_janela = self._calcular_tamanho_janela_proporcional(tamanho_janela)
        
        self.fps_anterior = time.time()
        self.fps_atual = 0
        
        # Classe 'person' no COCO dataset √© 0
        self.classe_pessoa = 0
        
        # Configura pyautogui
        pyautogui.FAILSAFE = False
        
        # Configura√ß√µes de visualiza√ß√£o
        self.mostrar_mascaras = True
        self.mostrar_contornos = True
        self.mostrar_bbox = True
        self.alpha_mascara = 0.5  # Transpar√™ncia da m√°scara
        
        # Thread-safety lock para infer√™ncia
        self._lock = Lock()
        
        # M√©todo de segmenta√ß√£o (custom ou plot nativo)
        self.usar_plot_nativo = False  # False = m√©todo custom, True = plot() nativo
        
        print(f"üéØ Modo: Segmenta√ß√£o de Pessoas na Tela")
        print(f"üéØ Confian√ßa m√≠nima: {confianca}")
        print(f"üñ•Ô∏è  Resolu√ß√£o da tela: {self.largura_tela}x{self.altura_tela}")
        print(f"üñ•Ô∏è  Resolu√ß√£o processada: {self.largura_processada}x{self.altura_processada}")
        print(f"üñ•Ô∏è  Fator de redu√ß√£o: {self.resolucao_captura:.2f}")
        print(f"ü™ü  Tamanho da janela: {self.tamanho_janela[0]}x{self.tamanho_janela[1]} (proporcional)")
        print(f"üé® Visualiza√ß√£o: M√°scaras={self.mostrar_mascaras}, Contornos={self.mostrar_contornos}, BBox={self.mostrar_bbox}")
        print(f"üîí Thread-safety: Habilitado")
        
    def _carregar_modelo(self, modelo):
        """
        Carrega o modelo YOLO, baixando automaticamente se necess√°rio.
        
        Args:
            modelo: Nome do modelo (ex: yolo11n-seg.pt)
            
        Returns:
            Modelo YOLO carregado
        """
        try:
            # Verifica se o arquivo existe localmente
            if os.path.exists(modelo):
                print(f"üìÅ Modelo encontrado localmente: {modelo}")
                return YOLO(modelo)
            else:
                print(f"üì• Modelo n√£o encontrado localmente. Baixando: {modelo}")
                print("‚è≥ Isso pode levar alguns minutos na primeira execu√ß√£o...")
                
                # Tenta baixar o modelo
                modelo_yolo = YOLO(modelo)
                print(f"‚úÖ Modelo baixado com sucesso: {modelo}")
                return modelo_yolo
                
        except Exception as e:
            print(f"‚ùå Erro ao carregar modelo {modelo}: {e}")
            print("üí° Verificando modelos dispon√≠veis...")
            
            # Lista modelos dispon√≠veis (YOLOv8 como fallback)
            modelos_disponiveis = [
                "yolov8n-seg.pt",  # YOLOv8 nano (mais r√°pido)
                "yolov8s-seg.pt",  # YOLOv8 small
                "yolov8m-seg.pt",  # YOLOv8 medium
                "yolov8l-seg.pt",  # YOLOv8 large
                "yolov8x-seg.pt",  # YOLOv8 extra large (mais preciso)
                # YOLO11 quando dispon√≠vel
                "yolo11n-seg.pt",
                "yolo11s-seg.pt", 
                "yolo11m-seg.pt",
                "yolo11l-seg.pt",
                "yolo11x-seg.pt"
            ]
            
            print("üìã Modelos de segmenta√ß√£o dispon√≠veis:")
            for i, modelo_disp in enumerate(modelos_disponiveis, 1):
                print(f"   {i}. {modelo_disp}")
            
            # Tenta usar modelos alternativos
            modelos_fallback = ["yolov8n-seg.pt", "yolov8s-seg.pt", "yolo11n-seg.pt"]
            
            for modelo_fallback in modelos_fallback:
                if modelo_fallback != modelo:
                    try:
                        print(f"üîÑ Tentando modelo alternativo: {modelo_fallback}")
                        return self._carregar_modelo(modelo_fallback)
                    except:
                        continue
            
            raise Exception("N√£o foi poss√≠vel carregar nenhum modelo de segmenta√ß√£o")
        
    def _verificar_gpu(self):
        """Verifica se CUDA est√° dispon√≠vel e retorna o dispositivo apropriado."""
        if torch.cuda.is_available():
            if torch.cuda.device_count() > 0:
                torch.cuda.set_device(0)
                return "cuda"
        return "cpu"
        
    def _calcular_tamanho_janela_proporcional(self, tamanho_desejado):
        """
        Calcula o tamanho da janela mantendo a propor√ß√£o da tela.
        
        Args:
            tamanho_desejado: (largura, altura) desejada
            
        Returns:
            (largura, altura) ajustada mantendo propor√ß√£o
        """
        largura_desejada, altura_desejada = tamanho_desejado
        
        # Calcula propor√ß√£o da tela
        proporcao_tela = self.largura_tela / self.altura_tela
        
        # Calcula propor√ß√£o desejada
        proporcao_desejada = largura_desejada / altura_desejada
        
        if proporcao_desejada > proporcao_tela:
            # Largura √© muito grande, ajusta pela altura
            nova_altura = altura_desejada
            nova_largura = int(altura_desejada * proporcao_tela)
        else:
            # Altura √© muito grande, ajusta pela largura
            nova_largura = largura_desejada
            nova_altura = int(largura_desejada / proporcao_tela)
        
        return (nova_largura, nova_altura)
        
    def capturar_tela(self):
        """Captura a tela usando pyautogui e redimensiona para melhor performance."""
        try:
            # Captura screenshot
            screenshot = pyautogui.screenshot()
            
            # Converte para numpy array
            frame = np.array(screenshot)
            
            # Converte RGB para BGR (OpenCV usa BGR)
            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
            
            # Redimensiona para melhor performance
            frame_redimensionado = cv2.resize(
                frame, 
                (self.largura_processada, self.altura_processada), 
                interpolation=cv2.INTER_AREA
            )
            
            return frame_redimensionado
            
        except Exception as e:
            print(f"‚ùå Erro na captura: {e}")
            return None
        
    def calcular_fps(self):
        """Calcula e atualiza o FPS atual."""
        agora = time.time()
        self.fps_atual = 1.0 / (agora - self.fps_anterior)
        self.fps_anterior = agora
        
    def segmentar_pessoas(self, frame):
        """
        Segmenta pessoas em um frame usando YOLOv8/YOLO11-seg.
        Aplicando as melhores pr√°ticas do modo predict da documenta√ß√£o oficial.
        Thread-safe para uso em aplica√ß√µes multithread.
        
        Args:
            frame: Frame da tela (j√° redimensionado)
            
        Returns:
            Frame com segmenta√ß√µes de pessoas desenhadas
        """
        # Thread-safety: usa lock para evitar conflitos em infer√™ncia multithread
        with self._lock:
            # Infer√™ncia de segmenta√ß√£o com GPU - apenas pessoas
            # Usando stream=True para melhor performance e thread-safety
            resultados = self.modelo.predict(
                frame, 
                imgsz=self.tamanho_img, 
                conf=self.confianca, 
                verbose=False,
                stream=True,  # Modo stream para melhor performance
                device=self.device,
                classes=[self.classe_pessoa],  # Filtra apenas pessoas
                iou=0.5,  # NMS IoU threshold
                max_det=20,  # M√°ximo de detec√ß√µes
                agnostic_nms=False,  # NMS class-agnostic
                retina_masks=True,  # M√°scaras de alta qualidade
                show=False,  # N√£o mostrar automaticamente
                save=False,  # N√£o salvar automaticamente
                save_txt=False,  # N√£o salvar labels
                save_conf=False,  # N√£o salvar confian√ßa
                save_crop=False,  # N√£o salvar crops
                show_labels=True,  # Mostrar labels
                show_conf=True,  # Mostrar confian√ßa
                vid_stride=1,  # Stride para v√≠deo
                line_width=2,  # Espessura das linhas (corrigido de line_thickness)
                visualize=False,  # N√£o visualizar features
                augment=False,  # Sem augmenta√ß√£o
                project=None,  # Projeto padr√£o
                name=None,  # Nome padr√£o
                exist_ok=False,  # N√£o sobrescrever
                half=False,  # Usar FP16 se dispon√≠vel
                dnn=False,  # Usar OpenCV DNN
                plots=False  # N√£o gerar plots
            )
            
            # Processa o resultado do stream
            resultado = next(resultados)  # Pega o primeiro resultado do stream
        
        # Cria c√≥pia do frame para desenhar
        frame_segmentado = frame.copy()
        
        # Processa cada detec√ß√£o
        num_pessoas = len(resultado.boxes)
        
        if num_pessoas > 0:
            # Obt√©m m√°scaras e caixas
            if hasattr(resultado, 'masks') and resultado.masks is not None:
                mascaras = resultado.masks.data.cpu().numpy()
                caixas = resultado.boxes.xyxy.cpu().numpy()
                confiancas = resultado.boxes.conf.cpu().numpy()
                
                for i in range(num_pessoas):
                    # Obt√©m m√°scara da pessoa
                    mascara = mascaras[i]
                    
                    # Redimensiona m√°scara para o tamanho do frame
                    mascara_redimensionada = cv2.resize(
                        mascara.astype(np.uint8), 
                        (frame.shape[1], frame.shape[0]), 
                        interpolation=cv2.INTER_LINEAR
                    )
                    
                    # Cria m√°scara bin√°ria
                    mascara_binaria = (mascara_redimensionada > 0.5).astype(np.uint8)
                    
                    # Cor da m√°scara (verde para pessoas)
                    cor_mascara = (0, 255, 0)  # Verde
                    
                    # Aplica m√°scara transparente
                    if self.mostrar_mascaras:
                        frame_segmentado = self._aplicar_mascara_transparente(
                            frame_segmentado, mascara_binaria, cor_mascara, self.alpha_mascara
                        )
                    
                    # Desenha contornos da m√°scara
                    if self.mostrar_contornos:
                        contornos, _ = cv2.findContours(
                            mascara_binaria, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
                        )
                        cv2.drawContours(frame_segmentado, contornos, -1, (255, 0, 0), 2)
                    
                    # Desenha bounding box
                    if self.mostrar_bbox:
                        x1, y1, x2, y2 = map(int, caixas[i])
                        conf = confiancas[i]
                        
                        # Desenha ret√¢ngulo
                        cv2.rectangle(frame_segmentado, (x1, y1), (x2, y2), (0, 255, 255), 2)
                        
                        # Adiciona texto com confian√ßa
                        texto = f"Pessoa: {conf:.2f}"
                        cv2.putText(frame_segmentado, texto, (x1, y1-10), 
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        return frame_segmentado, num_pessoas
        
    def _aplicar_mascara_transparente(self, frame, mascara, cor, alpha):
        """
        Aplica uma m√°scara transparente colorida sobre o frame.
        
        Args:
            frame: Frame original
            mascara: M√°scara bin√°ria
            cor: Cor da m√°scara (B, G, R)
            alpha: Transpar√™ncia (0.0 a 1.0)
            
        Returns:
            Frame com m√°scara aplicada
        """
        # Cria overlay colorido
        overlay = np.zeros_like(frame)
        overlay[mascara == 1] = cor
        
        # Aplica transpar√™ncia
        frame_resultado = cv2.addWeighted(frame, 1-alpha, overlay, alpha, 0)
        
        return frame_resultado
        
    def segmentar_pessoas_plot(self, frame):
        """
        Segmenta pessoas usando o m√©todo plot() da documenta√ß√£o oficial.
        M√©todo alternativo mais simples usando as funcionalidades nativas do YOLO.
        
        Args:
            frame: Frame da tela (j√° redimensionado)
            
        Returns:
            Frame com segmenta√ß√µes usando plot() nativo
        """
        # Thread-safety: usa lock para evitar conflitos em infer√™ncia multithread
        with self._lock:
            # Infer√™ncia usando m√©todo plot() da documenta√ß√£o oficial
            resultados = self.modelo.predict(
                frame,
                imgsz=self.tamanho_img,
                conf=self.confianca,
                verbose=False,
                stream=True,
                device=self.device,
                classes=[self.classe_pessoa],
                retina_masks=True,
                show=False,
                save=False
            )
            
            # Usa o m√©todo plot() nativo do YOLO
            resultado = next(resultados)
            frame_plotado = resultado.plot(
                labels=True,      # Mostrar labels
                boxes=True,       # Mostrar bounding boxes
                masks=True,       # Mostrar m√°scaras
                conf=True,        # Mostrar confian√ßa
                line_width=2      # Espessura das linhas (corrigido)
            )
            
            num_pessoas = len(resultado.boxes)
            return frame_plotado, num_pessoas
        
    def executar(self):
        """Executa o loop principal de segmenta√ß√£o."""
        print("\nüéÆ Controles:")
        print("   Q - Sair")
        print("   M - Toggle m√°scaras")
        print("   C - Toggle contornos")
        print("   B - Toggle bounding boxes")
        print("   +/- - Ajustar transpar√™ncia da m√°scara")
        print("   R - Reset configura√ß√µes")
        print("   S - Salvar frame atual")
        print("   F - Toggle informa√ß√µes da GPU")
        print("   H - Mostrar/ocultar ajuda")
        print("   P - Toggle m√©todo de segmenta√ß√£o (Custom/Plot nativo)")
        print("\nüöÄ Iniciando segmenta√ß√£o...")
        
        # Cria janela redimension√°vel
        cv2.namedWindow("Segmenta√ß√£o de Pessoas", cv2.WINDOW_NORMAL)
        cv2.resizeWindow("Segmenta√ß√£o de Pessoas", self.tamanho_janela[0], self.tamanho_janela[1])
        
        mostrar_ajuda = False
        mostrar_info_gpu = False
        
        try:
            while True:
                # Captura frame da tela
                frame = self.capturar_tela()
                if frame is None:
                    continue
                
                # Segmenta pessoas usando o m√©todo escolhido
                if self.usar_plot_nativo:
                    frame_segmentado, num_pessoas = self.segmentar_pessoas_plot(frame)
                else:
                    frame_segmentado, num_pessoas = self.segmentar_pessoas(frame)
                
                # Calcula FPS
                self.calcular_fps()
                
                # Adiciona informa√ß√µes na tela
                cv2.putText(frame_segmentado, f"FPS: {self.fps_atual:.1f}", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                cv2.putText(frame_segmentado, f"Pessoas: {num_pessoas}", 
                           (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                cv2.putText(frame_segmentado, f"Confian√ßa: {self.confianca:.2f}", 
                           (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                cv2.putText(frame_segmentado, f"Resolu√ß√£o: {self.largura_processada}x{self.altura_processada}", 
                           (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                cv2.putText(frame_segmentado, f"M√©todo: {'Plot nativo' if self.usar_plot_nativo else 'Custom'}", 
                           (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
                # Mostra informa√ß√µes da GPU se ativado
                if mostrar_info_gpu:
                    self._mostrar_info_gpu(frame_segmentado)
                
                # Mostra ajuda se ativado
                if mostrar_ajuda:
                    self._mostrar_ajuda(frame_segmentado)
                
                # Exibe o frame
                cv2.imshow("Segmenta√ß√£o de Pessoas", frame_segmentado)
                
                # Processa teclas
                tecla = cv2.waitKey(1) & 0xFF
                
                if tecla == ord('q'):
                    break
                elif tecla == ord('m'):
                    self.mostrar_mascaras = not self.mostrar_mascaras
                    print(f"üé® M√°scaras: {'ON' if self.mostrar_mascaras else 'OFF'}")
                elif tecla == ord('c'):
                    self.mostrar_contornos = not self.mostrar_contornos
                    print(f"üé® Contornos: {'ON' if self.mostrar_contornos else 'OFF'}")
                elif tecla == ord('b'):
                    self.mostrar_bbox = not self.mostrar_bbox
                    print(f"üé® Bounding Boxes: {'ON' if self.mostrar_bbox else 'OFF'}")
                elif tecla == ord('+') or tecla == ord('='):
                    self.alpha_mascara = min(1.0, self.alpha_mascara + 0.1)
                    print(f"üé® Transpar√™ncia da m√°scara: {self.alpha_mascara:.1f}")
                elif tecla == ord('-'):
                    self.alpha_mascara = max(0.0, self.alpha_mascara - 0.1)
                    print(f"üé® Transpar√™ncia da m√°scara: {self.alpha_mascara:.1f}")
                elif tecla == ord('r'):
                    self.mostrar_mascaras = True
                    self.mostrar_contornos = True
                    self.mostrar_bbox = True
                    self.alpha_mascara = 0.5
                    print("üîÑ Configura√ß√µes resetadas")
                elif tecla == ord('s'):
                    timestamp = time.strftime("%Y%m%d_%H%M%S")
                    nome_arquivo = f"segmentacao_pessoas_{timestamp}.jpg"
                    cv2.imwrite(nome_arquivo, frame_segmentado)
                    print(f"üíæ Frame salvo: {nome_arquivo}")
                elif tecla == ord('f'):
                    mostrar_info_gpu = not mostrar_info_gpu
                    print(f"üìä Info GPU: {'ON' if mostrar_info_gpu else 'OFF'}")
                elif tecla == ord('h'):
                    mostrar_ajuda = not mostrar_ajuda
                    print(f"‚ùì Ajuda: {'ON' if mostrar_ajuda else 'OFF'}")
                elif tecla == ord('p'):
                    self.usar_plot_nativo = not self.usar_plot_nativo
                    print(f"üé® M√©todo de segmenta√ß√£o: {'Custom' if not self.usar_plot_nativo else 'Plot nativo'}")
                    
        except KeyboardInterrupt:
            print("\n‚èπÔ∏è  Interrompido pelo usu√°rio")
        finally:
            self.liberar()
            
    def _mostrar_info_gpu(self, frame):
        """Mostra informa√ß√µes da GPU no frame."""
        if self.device == "cuda":
            memoria_usada = torch.cuda.memory_allocated(0) / 1024**3
            memoria_total = torch.cuda.get_device_properties(0).total_memory / 1024**3
            utilizacao = (memoria_usada / memoria_total) * 100
            
            cv2.putText(frame, f"GPU: {torch.cuda.get_device_name()}", 
                       (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
            cv2.putText(frame, f"Mem√≥ria: {memoria_usada:.1f}GB / {memoria_total:.1f}GB", 
                       (10, 175), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
            cv2.putText(frame, f"Utiliza√ß√£o: {utilizacao:.1f}%", 
                       (10, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        else:
            cv2.putText(frame, "GPU: CPU", 
                       (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
            
    def _mostrar_ajuda(self, frame):
        """Mostra ajuda na tela."""
        ajuda = [
            "Q - Sair",
            "M - Toggle m√°scaras",
            "C - Toggle contornos", 
            "B - Toggle bounding boxes",
            "+/- - Ajustar transpar√™ncia",
            "R - Reset configura√ß√µes",
            "S - Salvar frame",
            "F - Info GPU",
            "H - Toggle ajuda",
            "P - Toggle m√©todo de segmenta√ß√£o"
        ]
        
        y_offset = 250
        for linha in ajuda:
            cv2.putText(frame, linha, (10, y_offset), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            y_offset += 20
            
    def liberar(self):
        """Libera recursos."""
        cv2.destroyAllWindows()
        if self.device == "cuda":
            torch.cuda.empty_cache()
        print("üßπ Recursos liberados")

def main():
    """Fun√ß√£o principal."""
    parser = argparse.ArgumentParser(description="Segmenta√ß√£o de pessoas em tempo real")
    parser.add_argument("--modelo", default="yolov8n-seg.pt", 
                       help="Modelo YOLOv8/YOLO11-seg (padr√£o: yolov8n-seg.pt)")
    parser.add_argument("--confianca", type=float, default=0.5,
                       help="Limiar de confian√ßa (0.0 a 1.0, padr√£o: 0.5)")
    parser.add_argument("--tamanho", type=int, default=640,
                       help="Tamanho da imagem para infer√™ncia (padr√£o: 640)")
    parser.add_argument("--resolucao", type=float, default=0.5,
                       help="Fator de redu√ß√£o da resolu√ß√£o (0.1 a 1.0, padr√£o: 0.5)")
    parser.add_argument("--janela", nargs=2, type=int, default=[800, 600],
                       help="Tamanho da janela largura altura (padr√£o: 800 600)")
    
    args = parser.parse_args()
    
    # Valida argumentos
    if not (0.0 <= args.confianca <= 1.0):
        print("‚ùå Erro: Confian√ßa deve estar entre 0.0 e 1.0")
        return
        
    if not (0.1 <= args.resolucao <= 1.0):
        print("‚ùå Erro: Resolu√ß√£o deve estar entre 0.1 e 1.0")
        return
    
    try:
        # Cria e executa segmentador
        segmentador = SegmentadorPessoas(
            modelo=args.modelo,
            confianca=args.confianca,
            tamanho_img=args.tamanho,
            resolucao_captura=args.resolucao,
            tamanho_janela=tuple(args.janela)
        )
        
        segmentador.executar()
        
    except Exception as e:
        print(f"‚ùå Erro: {e}")
        print("üí° Dica: Certifique-se de que o modelo YOLO11-seg est√° dispon√≠vel")
        print("üí° Execute: pip install ultralytics")

if __name__ == "__main__":
    main() 